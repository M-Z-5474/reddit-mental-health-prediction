                 
# ğŸ§  Reddit Mental Health Prediction

This repository presents an end-to-end machine learning pipeline to **predict mental health conditions** (Stress, Anxiety, Depression) using **Reddit posts**. The goal is to explore how **natural language processing (NLP)** and supervised learning can be applied to unstructured social media text to assist in early detection of mental health issues.

---

## ğŸ“ Project Structure

```

reddit-mental-health-prediction/
â”‚
â”œâ”€â”€ results/ # ğŸ“Š Evaluation Visuals
â”‚   â”œâ”€â”€ confusion_matrix_svm.png
â”‚   â”œâ”€â”€ roc_curve_svm_multiclass.png
â”‚   â”œâ”€â”€ model_accuracy_comparison.png
â”‚   â””â”€â”€ model_performance_comparison.png
|
â”œâ”€â”€ README.md # ğŸ“˜ Project overview
â”œâ”€â”€ best_model.pkl # ğŸ’¾ Trained best-performing model
â”œâ”€â”€ reddit_mental_health_prediction.ipynb # ğŸ§ª Full ML pipeline in one notebook
â”œâ”€â”€ reddit_dataset.csv # dataset which used for project
â”œâ”€â”€ requirements.txt # ğŸ“¦ Python dependencies

```
---

## ğŸ¯ Project Objective

The aim is to:
- Use **Reddit mental health posts** as unstructured data.
- Apply **NLP preprocessing** (tokenization, stopword removal, lemmatization).
- Perform Exploratory Data Analysis (EDA) to understand class distribution, word frequency, and insights.
- Extract features using **TF-IDF**
- Split data using an 80/20 train-test ratio for model training and evaluation.
- Train and evaluate following models 
- ğŸ’  Support Vector Machine (SVM)
- ğŸŒ³ Random Forest
- âš¡ XGBoost
- ğŸ§  Artificial Neural Network (ANN)
- ğŸ“ˆ Logistic Regression
- ğŸ“Š NaÃ¯ve Bayes  

- Identify which algorithm performs best in predicting mental health categories.

---

## ğŸ“š Dataset

ğŸ“¥ **Download Reddit Dataset**: [`reddit_dataset.csv`](./reddit_dataset.csv)
---

## ğŸ“Š Target Labels
According to research....
- **0 â†’ Stress**
- **1 â†’ Depression**
- **2 â†’ Anxiety**

---


## ğŸ“¦ Libraries used:

* pandas
* numpy
* scikit-learn
* nltk
* matplotlib
* seaborn
* joblib


---

## ğŸ“ˆ Model Evaluation

The models are evaluated using:

* Confusion Matrix
* Accuracy Comparison
* Precision / Recall / F1-Score
* ROC-AUC

Results are saved under the `results/` folder.

---


## ğŸ“¦ Output

ğŸ” **Best Performing Model:**
- [`best_model.pkl`](./best_model.pkl) â€” Serialized model file using `joblib`.

ğŸ“Š **Evaluation Visuals (from `/results/`):**

- ğŸ” **Confusion Matrix**  
  ![Confusion Matrix](./results/confusion_matrix_svm.png)

- ğŸ¯ **ROC Curve (Multiclass)**  
  ![ROC Curve](./results/roc_curve_svm_multiclass.png)

- ğŸ“ˆ **Model Accuracy Comparison**  
  ![Accuracy Comparison](./results/model_accuracy_comparison.png)

- ğŸ§ª **Model Performance Comparison (Precision/Recall/F1)**  
  ![Performance Comparison](./results/model_performance_comparison.png)

ğŸ“ **Note**: All evaluation assets are saved in the [`results/`](./results) folder.

---

## ğŸš€ Future Work

ğŸš€ Expand to include structured survey data

ğŸŒ Deploy as an interactive web app

ğŸ’¬ Integrate sentiment analysis and topic modeling


---

## ğŸ™‹â€â™‚ï¸ Author

**Muhammad Zain Mushtaq**

ğŸ”— GitHub: https://github.com/M-Z-5474

ğŸ“§ Email: m.zainmushtaq74@gmail.com

ğŸ”— LinkedIn: https://www.linkedin.com/in/muhammad-zain-m-a75163358/

---

## ğŸŒŸ If you like this project, please consider giving it a â­ on GitHub!
---


